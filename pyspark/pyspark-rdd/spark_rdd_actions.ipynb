{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('PySparkRddActions') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[(\"Z\", 1),(\"A\", 20),(\"B\", 30),(\"C\", 40),(\"B\", 30),(\"B\", 60)]\n",
    "inputRDD = spark.sparkContext.parallelize(data)\n",
    "listRdd = spark.sparkContext.parallelize([1,2,3,4,5,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#aggregate\n",
    "seqOp = (lambda x, y: x + y)\n",
    "combOp = (lambda x, y: x + y)\n",
    "agg=listRdd.aggregate(0, seqOp, combOp)\n",
    "print(agg) # output 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 20)\n"
     ]
    }
   ],
   "source": [
    "#aggregate 2\n",
    "listRddPartitioned = spark.sparkContext.parallelize(range(20),6)\n",
    "seqOp2 = (lambda x, y: (x[0] + y, x[1] + 1))\n",
    "combOp2 = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "agg2=listRddPartitioned.aggregate((0, 0), seqOp2, combOp2)\n",
    "print(agg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "agg2=listRdd.treeAggregate(0,seqOp, combOp)\n",
    "print(agg2) # output 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#fold\n",
    "from operator import add\n",
    "foldRes=listRdd.fold(0, add)\n",
    "print(foldRes) # output 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#reduce\n",
    "redRes=listRdd.reduce(add)\n",
    "print(redRes) # output 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#treeReduce. This is similar to reduce\n",
    "add = lambda x, y: x + y\n",
    "redRes=listRdd.treeReduce(add)\n",
    "print(redRes) # output 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "#Collect\n",
    "data = listRdd.collect()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count : 7\n",
      "countApprox : 7\n",
      "countApproxDistinct : 5\n",
      "countApproxDistinct : 5\n"
     ]
    }
   ],
   "source": [
    "#count, countApprox, countApproxDistinct\n",
    "print(\"Count : \"+str(listRdd.count()))\n",
    "#Output: Count : 20\n",
    "print(\"countApprox : \"+str(listRdd.countApprox(1200)))\n",
    "#Output: countApprox : (final: [7.000, 7.000])\n",
    "print(\"countApproxDistinct : \"+str(listRdd.countApproxDistinct()))\n",
    "#Output: countApproxDistinct : 5\n",
    "print(\"countApproxDistinct : \"+str(inputRDD.countApproxDistinct()))\n",
    "#Output: countApproxDistinct : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#countByValue, countByValueApprox\n",
    "print(\"countByValue :  \"+str(listRdd.countByValue()))\n",
    "\n",
    "\n",
    "#first\n",
    "print(\"first :  \"+str(listRdd.first()))\n",
    "#Output: first :  1\n",
    "print(\"first :  \"+str(inputRDD.first()))\n",
    "#Output: first :  (Z,1)\n",
    "\n",
    "#top\n",
    "print(\"top : \"+str(listRdd.top(2)))\n",
    "#Output: take : 5,4\n",
    "print(\"top : \"+str(inputRDD.top(2)))\n",
    "#Output: take : (Z,1),(C,40)\n",
    "\n",
    "#min\n",
    "print(\"min :  \"+str(listRdd.min()))\n",
    "#Output: min :  1\n",
    "print(\"min :  \"+str(inputRDD.min()))\n",
    "#Output: min :  (A,20)  \n",
    "\n",
    "#max\n",
    "print(\"max :  \"+str(listRdd.max()))\n",
    "#Output: max :  5\n",
    "print(\"max :  \"+str(inputRDD.max()))\n",
    "#Output: max :  (Z,1)\n",
    "\n",
    "#take, takeOrdered, takeSample\n",
    "print(\"take : \"+str(listRdd.take(2)))\n",
    "#Output: take : 1,2\n",
    "print(\"takeOrdered : \"+ str(listRdd.takeOrdered(2)))\n",
    "#Output: takeOrdered : 1,2\n",
    "print(\"take : \"+str(listRdd.takeSample()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdf56476358ac535b91ee7f3f9cd0c09fe6490241d31b6256d2c842c495b64a5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
